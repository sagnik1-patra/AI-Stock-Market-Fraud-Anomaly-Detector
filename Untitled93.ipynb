{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd8d0209-7413-4809-b08c-592c6c0c2f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset: C:\\Users\\NXTWAVE\\Downloads\\AI Stock Market Fraud & Anomaly Detector\\archive\\financial_anomaly_data.csv\n",
      "[INFO] Shape: (217441, 7)\n",
      "[INFO] Columns: ['Timestamp', 'TransactionID', 'AccountID', 'Amount', 'Merchant', 'TransactionType', 'Location']\n",
      "[INFO] Numeric features used: ['Amount']\n",
      "[INFO] Processed data saved: C:\\Users\\NXTWAVE\\Downloads\\AI Stock Market Fraud & Anomaly Detector\\processed_trades.h5\n",
      "[INFO] Training AIS (IsolationForest)...\n",
      "[INFO] AIS model saved: C:\\Users\\NXTWAVE\\Downloads\\AI Stock Market Fraud & Anomaly Detector\\anomaly_model.pkl\n",
      "[INFO] Synthetic labels created → Fraud: 10879, Normal: 206562\n",
      "[INFO] Training CSA (RandomForest)...\n",
      "[RESULT] CSA Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     41313\n",
      "           1       1.00      1.00      1.00      2176\n",
      "\n",
      "    accuracy                           1.00     43489\n",
      "   macro avg       1.00      1.00      1.00     43489\n",
      "weighted avg       1.00      1.00      1.00     43489\n",
      "\n",
      "[INFO] CSA model saved: C:\\Users\\NXTWAVE\\Downloads\\AI Stock Market Fraud & Anomaly Detector\\fraud_model.pkl\n",
      "[INFO] Hybrid predictions saved: C:\\Users\\NXTWAVE\\Downloads\\AI Stock Market Fraud & Anomaly Detector\\hybrid_predictions.csv\n",
      "[INFO] Metadata saved: C:\\Users\\NXTWAVE\\Downloads\\AI Stock Market Fraud & Anomaly Detector\\build_metadata.yaml\n",
      "[DONE] Hybrid AIS + CSA pipeline complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ---------------- CONFIG ---------------- #\n",
    "BASE_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\AI Stock Market Fraud & Anomaly Detector\"\n",
    "DATA_PATH = os.path.join(BASE_DIR, \"archive\", \"financial_anomaly_data.csv\")\n",
    "\n",
    "OUT_H5   = os.path.join(BASE_DIR, \"processed_trades.h5\")\n",
    "OUT_AIS  = os.path.join(BASE_DIR, \"anomaly_model.pkl\")\n",
    "OUT_CSA  = os.path.join(BASE_DIR, \"fraud_model.pkl\")\n",
    "OUT_JSON = os.path.join(BASE_DIR, \"finguard_report.json\")\n",
    "OUT_YAML = os.path.join(BASE_DIR, \"build_metadata.yaml\")\n",
    "OUT_PRED = os.path.join(BASE_DIR, \"hybrid_predictions.csv\")\n",
    "\n",
    "# ---------------- LOAD DATA ---------------- #\n",
    "print(f\"[INFO] Loading dataset: {DATA_PATH}\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"[INFO] Shape:\", df.shape)\n",
    "print(\"[INFO] Columns:\", df.columns.tolist())\n",
    "\n",
    "# ---------------- FEATURE ENGINEERING ---------------- #\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if not num_cols:\n",
    "    raise ValueError(\"No numeric columns found!\")\n",
    "\n",
    "print(\"[INFO] Numeric features used:\", num_cols)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "# Save processed data\n",
    "pd.DataFrame(X_scaled, columns=num_cols).to_hdf(OUT_H5, key=\"trades\", mode=\"w\")\n",
    "print(f\"[INFO] Processed data saved: {OUT_H5}\")\n",
    "\n",
    "# ---------------- AIS: ANOMALY ISOLATION STRATEGY ---------------- #\n",
    "print(\"[INFO] Training AIS (IsolationForest)...\")\n",
    "ais = IsolationForest(n_estimators=200, contamination=0.05, random_state=42)\n",
    "ais.fit(X_scaled)\n",
    "\n",
    "anom_scores = -ais.decision_function(X_scaled)  # higher = more anomalous\n",
    "anom_flags = ais.predict(X_scaled)              # -1 anomaly, 1 normal\n",
    "joblib.dump(ais, OUT_AIS)\n",
    "print(f\"[INFO] AIS model saved: {OUT_AIS}\")\n",
    "\n",
    "# ---------------- SYNTHETIC LABELS FOR CSA ---------------- #\n",
    "# Use top 5% anomaly scores as fraud=1, others=0\n",
    "threshold = np.percentile(anom_scores, 95)\n",
    "labels = (anom_scores >= threshold).astype(int)\n",
    "print(f\"[INFO] Synthetic labels created → Fraud: {labels.sum()}, Normal: {len(labels) - labels.sum()}\")\n",
    "\n",
    "# ---------------- CSA: CLASSIFIER SUPERVISED APPROACH ---------------- #\n",
    "print(\"[INFO] Training CSA (RandomForest)...\")\n",
    "Xtr, Xte, ytr, yte = train_test_split(X_scaled, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "csa = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "csa.fit(Xtr, ytr)\n",
    "ypred = csa.predict(Xte)\n",
    "\n",
    "print(\"[RESULT] CSA Report:\\n\", classification_report(yte, ypred, zero_division=0))\n",
    "joblib.dump(csa, OUT_CSA)\n",
    "print(f\"[INFO] CSA model saved: {OUT_CSA}\")\n",
    "\n",
    "# ---------------- HYBRID MODEL ---------------- #\n",
    "fraud_probs = csa.predict_proba(X_scaled)[:, 1]\n",
    "anom_norm = (anom_scores - anom_scores.min()) / (anom_scores.max() - anom_scores.min())\n",
    "\n",
    "# Hybrid score: equal weights (can be tuned)\n",
    "hybrid_score = 0.5 * anom_norm + 0.5 * fraud_probs\n",
    "hybrid_pred = (hybrid_score > 0.6).astype(int)  # adjustable threshold\n",
    "\n",
    "# ---------------- SAVE HYBRID PREDICTIONS ---------------- #\n",
    "df[\"AIS_AnomalyScore\"] = anom_scores\n",
    "df[\"CSA_FraudProb\"] = fraud_probs\n",
    "df[\"HybridScore\"] = hybrid_score\n",
    "df[\"HybridPrediction\"] = hybrid_pred\n",
    "\n",
    "df.to_csv(OUT_PRED, index=False)\n",
    "print(f\"[INFO] Hybrid predictions saved: {OUT_PRED}\")\n",
    "\n",
    "# ---------------- REPORT JSON ---------------- #\n",
    "report = {\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"dataset_shape\": df.shape,\n",
    "    \"features_used\": num_cols,\n",
    "    \"AIS_model\": \"IsolationForest\",\n",
    "    \"CSA_model\": \"RandomForestClassifier\",\n",
    "    \"hybrid_threshold\": 0.6,\n",
    "    \"counts\": {\n",
    "        \"total\": int(len(df)),\n",
    "        \"AIS_anomalies\": int((anom_flags == -1).sum()),\n",
    "        \"CSA_predicted_fraud\": int(labels.sum()),\n",
    "        \"Hybrid_predicted_fraud\": int(hybrid_pred.sum())\n",
    "    },\n",
    "    \"outputs\": {\n",
    "        \"processed_data\": OUT_H5,\n",
    "        \"AIS_model\": OUT_AIS,\n",
    "        \"CSA_model\": OUT_CSA,\n",
    "        \"hybrid_predictions\": OUT_PRED\n",
    "    }\n",
    "}\n",
    "with open(OUT_JSON, \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "# ---------------- METADATA YAML ---------------- #\n",
    "with open(OUT_YAML, \"w\") as f:\n",
    "    yaml.dump(report, f)\n",
    "print(f\"[INFO] Metadata saved: {OUT_YAML}\")\n",
    "\n",
    "print(\"[DONE] Hybrid AIS + CSA pipeline complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1477bc-607a-461b-998d-65efc59f47a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
